{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchtext 라이브러리로 텍스트 분류 <hr>\n",
    "- 1단계 : 데이터 전처리 => 숫자형식으로 변환\n",
    "- 2단계 : 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1-1] 데이터 준비 => 내장 데이터셋 활용\n",
    "- AGNEWS 데이터셋 반복자 : 레이블(label) + 문장의 튜풀(tuple) 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.17.2'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchtext\n",
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import AG_NEWS\n",
    "\n",
    "# DataPipe 타입 >>> iterator 타입 형변환\n",
    "train_iter = iter(AG_NEWS(split = 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 확인 => (label, text), label : 1 ~ 4\n",
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 데이터 전처리 파이프라인 준비\n",
    "- 어휘집(vocab), 단어 벡터(word vector), 토크나이저(tokenizer)\n",
    "- 가공되지 않은 텍스트 문자열에 대한 데이터 처리 빌딩 블록\n",
    "- 일반적인 NLP 데이터 처리\n",
    "    - 첫번째 단계 : 가공되지 않은 학습 데이터셋으로 어휘집 생성  \n",
    "    ==> 토큰 목록 또는 반복자 받는 내장 팩토리 함수 (factory function) : ``bulid_vocab_from_iterator``\n",
    "    - 사용자는 어휘집에 추가할 특수 기호(special symbol) 전달 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 적기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토커나이즈 생성\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# 뉴스 학습 데이터 추출\n",
    "train_iter = AG_NEWS(split = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 제너레이터 함수 : 데이터 추출하여 토큰화\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        # 라벨, 텍스트 => 텍스트 토큰화\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build_vocab_from_iterator의 파라미터\n",
    "- iterator – Iterator used to build Vocab. Must yield list or iterator of tokens. 어휘사전을 만들 때 쓰이는 iterator.\n",
    "- min_freq – The minimum frequency needed to include a token in the vocabulary. 최소 빈도 수 (최소 빈도 수를 늘리면 어휘사전에 들어가는 숫자 감소)\n",
    "- specials – Special symbols to add. The order of supplied tokens will be preserved.\n",
    "- special_first – Indicates whether to insert symbols at the beginning or at the end.\n",
    "- max_tokens – If provided, creates the vocab from the max_tokens - len(specials) most frequent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어사전 생성\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials = ['<unk>'])\n",
    "\n",
    "# <UNK> 인덱스 0으로 설정\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 475, 21, 30, 5297]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['<unk>', 'here', 'is', 'an', 'example'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 => 정수 인코딩\n",
    "text_pipeline = lambda x : vocab(tokenizer(x))\n",
    "\n",
    "# 레이블 => 정수 인코딩\n",
    "label_pipeline = lambda x : int(x) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 데이터 배치(batch)와 반복자 생성\n",
    "- torch.utils.data.DataLoader : getitem(), len() 구현한 맵 형태(map-style)\n",
    "- collate_fn() : DataLoader로부터 생성된 샘플 배치 함수  \n",
    "==> 입력 : DataLoader에 배치 크기(batch size)가 있는 배치(batch) 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 배치 크기만큼 데이터셋 반환 함수\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "\n",
    "    # 1개씩 뉴스기사, 라벨 추출해서 저장\n",
    "    for (_label, _text) in batch:\n",
    "        # 라벨 인코딩 후 저장\n",
    "        label_list.append(label_pipeline(_label))\n",
    "\n",
    "        # 텍스트 인코딩 후 저장\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype = torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "\n",
    "        # 텍스트 offset 즉, 텍스트 크기/길이 저장\n",
    "        offsets.append(processed_text.size(0))\n",
    "    \n",
    "    label_list = torch.tensor(label_list, dtype = torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim = 0)\n",
    "    text_list = torch.cat(text_list)\n",
    "\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = AG_NEWS(split = 'train')\n",
    "dataloader = DataLoader(train_iter,\n",
    "                        batch_size = 8,\n",
    "                        shuffle = True,\n",
    "                        collate_fn = collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num class : 4   vocab size : 95811\n"
     ]
    }
   ],
   "source": [
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(f'num class : {num_class}   vocab size : {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 2, 3, 0, 3, 0, 1, 0]) tensor([  510,  8920,   761,  4363,  3286,    13,    31,    14,    31,    15,\n",
      "          510,  3612,    22,    47,  3286,    11,   761,  4363,    56,     3,\n",
      "         2758,   211,   420,    10,     2,   466,  1444,     6,  2198,   709,\n",
      "          207,     3,   103,    21,  9551,    24,     2,   128,   790,     8,\n",
      "          103,   306,   453,  1706,   104,   170,     4,    23,  8347,    11,\n",
      "            5,  1413,     6,  7359,     1,  4130,    12,     9,  4320,   400,\n",
      "         2294,   354,   588,     3, 49973,    84,  4320,   278,   400,    11,\n",
      "         4130,  2196,     3,   358,    12,     9,   238,  5521,     3,  3336,\n",
      "            2,    54,    12,     9,   373,    11,     5,   395,     1,   108,\n",
      "          106,   354,   588,     8,    33,   465,     4,   376,    96,    34,\n",
      "          664,    10,   503,    56,     3, 49973,  1352,    26,     1, 13282,\n",
      "            7, 15915,  8046,   200,   101, 44329,    13, 13282, 44329,    14,\n",
      "         7551,   801, 15915,  1789, 58223,     4,    37, 23803,     1, 41991,\n",
      "          110,    67,   824,    16,    83,  2080,    25,    18,     5,   932,\n",
      "        44032,     1,   165,    39,     4,  1115, 95618, 53604,     1, 36071,\n",
      "            1,     4,   203,  7564,  3876,     2, 10485,  1246,    16,    83,\n",
      "         2294, 67008,   303,   165,    39,     4, 15529,  1992, 28803,     1,\n",
      "         4001,     1,   282,   122,  4859,    17,    67, 78315,   915,     4,\n",
      "          990,    61, 10485,     8, 18251,    61,   116,    48, 13282,  1299,\n",
      "        63086,   122,   990,     5,  7115, 44032,    17, 23536,  7387,   628,\n",
      "          130, 60922,     1,   229,    21,     6,  1213,     2,   384,  6991,\n",
      "          802,    45,   165,    39,     4, 71359,    25,     1, 30704,   165,\n",
      "         1891,   798,     4,   423,   475,    21,  1992,     5,   802,     6,\n",
      "         1299, 57561,   101,     1, 38463,     1, 71417, 54635,     1,  4610,\n",
      "            1, 23336,     1, 54609,  1443,  4143,   148,  5092,   273,  2324,\n",
      "         7035,     3,  5022,    84,     5,  3126,   485,   326,    17,   131,\n",
      "           36,   273,  6213,  5087,   123,  3387,    11,  4831,    20,     2,\n",
      "         1443,  4143,  1025,     7,    70,   302,    67,   889,     4,  7904,\n",
      "        10499,   847,  7562,     3,  4930,  4742,    10,  2267,  4930,   806,\n",
      "           18,  1606,  1124,   219,  7562,    10,  2024,    38,   118,  2510,\n",
      "            1,     9,     1,   699,   198,  1684,  3088,  2042,     7,  2286,\n",
      "          754,  4388,   995,    13,    27,    14,    15,     2,  2042,     6,\n",
      "          141,   188,   199,   125,  3225,  3088,    35,   794,     7,   211,\n",
      "          699,    10,    56,    10,  4526,     6,  4295,     7,     5, 11733,\n",
      "         2132,    63,     2,   100,     6,  4669,  3699,  3351,     1, 26110,\n",
      "          402,  2729,   141,  5377, 11875, 13243,  3518, 26700,   424,  4658,\n",
      "        16064, 26110,     7,  4124,     6,     2,  1624,     4,   109,     2,\n",
      "          313,   509,    12,     9,  9727,    96,     3,    45,    33,   189,\n",
      "            2,   276,   707,   160,     4,  2916,     1,    51,     1,     9,\n",
      "            1, 10274,   113,     4,   375,  1147, 17763,   351,     3,  1147,\n",
      "           15, 12901, 21415,   212,     5,   372,  1823,   336,    10,  1147,\n",
      "           16,     9, 66768, 82753,     3,  7226,   283,    29,   884,     5,\n",
      "         3362, 17367,  1005,    17,    93,    39,   275,     2,    88,   159,\n",
      "           16,   170,     4,    48,   346,     3,     8,     2,   767,   192,\n",
      "        17763,    57,   115,     7,     2,   127,   426,     6,     2,   313,\n",
      "          433,    16,     9,   909,  1082,     1,     7,     5,   389,  1040,\n",
      "           89,    72,   240,     3,     2,   767,  5951,   113,    29,    40,\n",
      "         6801,   296,     4,  6836,  8216,     7,    40,  1717,     8,  7347,\n",
      "         3958,     4, 12412,     3,   103,    95,    39,  7057,    40,   296,\n",
      "         1321,    29,     2,  1601,  4931,    97,     1,     1,     1]) tensor([  0,  55, 109, 244, 282, 301, 349, 387])\n"
     ]
    }
   ],
   "source": [
    "for labels, texts, offsets in dataloader:\n",
    "    print(labels, texts, offsets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# 모델 설계\n",
    "# 입력층 : EmbeddingBag Layer - 레이어와 분류(classification) 목적을 위한 선형 레이어, 텍스트의 길이는 오프셋(offset)\n",
    "# 은닉층 : Linear - 4개 클래스 분류\n",
    "class TextModel(nn.Module):\n",
    "    def __init__(self, VOCAB_SIZE, EMBEDD_DIM, HIDDEN_SIZE, NUM_CLASS):\n",
    "        super().__init__()\n",
    "        # 모델 구성 층 정의\n",
    "        self.embedding = nn.EmbeddingBag(VOCAB_SIZE, EMBEDD_DIM, sparse = False)\n",
    "        # self.rnn == nn.RNN(EMBEDD_DIM, HIDDEN_DIM)\n",
    "        self.fc = nn.Linear(EMBEDD_DIM, NUM_CLASS)\n",
    "        self.init_weights()\n",
    "\n",
    "    # 가중치 초기화\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "    # 순방향 학습 진행\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        # output, _ = self.rnn(embedded)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\Torch_NLP38\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    }
   ],
   "source": [
    "# 학습관련 하이퍼파라미터와 인스턴스\n",
    "HIDDEN_SIZE = 3\n",
    "EMBEDD_DIM = 64\n",
    "VOCAB_SIZE = len(vocab)\n",
    "NUM_CLASS = len(set([label for label, _ in train_iter]))\n",
    "EPOCHS = 10\n",
    "LR = 5\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# 학습관련 인스턴스\n",
    "MODEL = TextModel(VOCAB_SIZE, EMBEDD_DIM, HIDDEN_SIZE, NUM_CLASS).to(device)\n",
    "\n",
    "CRITERION = nn.CrossEntropyLoss()\n",
    "OPTIMIZER = optim.SGD(MODEL.parameters(), lr = LR)\n",
    "SCHEDULER = optim.lr_scheduler.StepLR(OPTIMIZER, step_size = 1.0, gamma = 0.1)  # learning rate를 줄이는 용도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, epoch):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    # 학습 평가 관련 변수들\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 300\n",
    "\n",
    "    # 배치 학습 진행\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "\n",
    "        label, text, offsets = label.to(device), text.to(device), offsets.to(device)\n",
    "\n",
    "        # 학습진행\n",
    "        predicted_label = MODEL(text, offsets)\n",
    "        # print(f'predicted_label : {predicted_label.shape}  label : {label.shape}')\n",
    "\n",
    "        # 손실 계산 및 W, b 업데이트\n",
    "        OPTIMIZER.zero_grad()\n",
    "        loss = CRITERION(predicted_label, label)\n",
    "\n",
    "        # 기울기 소실 및 폭주 예방을 위한 양극단 값 자르기\n",
    "        torch.nn.utils.clip_grad_norm_(MODEL.parameters(), max_norm = 0.1)\n",
    "        OPTIMIZER.step()\n",
    "\n",
    "        # 배치 학습 평가\n",
    "        total_acc += (predicted_label.argmax(1) ==label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            print(f\"epoch : {epoch} batch : {idx} loss : {loss.item()}\")\n",
    "            print(f\"Accuracy : {total_acc/total_count}\")\n",
    "            total_acc, total_count = 0,0\n",
    "            \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion):\n",
    "    \n",
    "    model.eval()    \n",
    "    total_acc, total_count = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = CRITERION(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "            \n",
    "    return total_acc / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text), dtype=torch.int64).to(device)\n",
    "        text = text.unsqueeze(0)\n",
    "        offsets = torch.tensor([0]).to(device)\n",
    "        predicted_label = model(text, offsets)\n",
    "        return predicted_label.argmax(1).item() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1 batch : 300 loss : 1.4147255420684814\n",
      "Accuracy : 0.24543189368770765\n",
      "epoch : 1 Accuracy : 0.25021666666666664\n",
      "epoch : 2 batch : 300 loss : 1.4797996282577515\n",
      "Accuracy : 0.24335548172757476\n",
      "epoch : 2 Accuracy : 0.25021666666666664\n",
      "epoch : 3 batch : 300 loss : 1.4044699668884277\n",
      "Accuracy : 0.2558139534883721\n",
      "epoch : 3 Accuracy : 0.25021666666666664\n",
      "epoch : 4 batch : 300 loss : 1.3760309219360352\n",
      "Accuracy : 0.2479235880398671\n",
      "epoch : 4 Accuracy : 0.25021666666666664\n",
      "epoch : 5 batch : 300 loss : 1.3967318534851074\n",
      "Accuracy : 0.2404485049833887\n",
      "epoch : 5 Accuracy : 0.25021666666666664\n",
      "epoch : 6 batch : 300 loss : 1.3563001155853271\n",
      "Accuracy : 0.23421926910299004\n",
      "epoch : 6 Accuracy : 0.25021666666666664\n",
      "epoch : 7 batch : 300 loss : 1.3982785940170288\n",
      "Accuracy : 0.24750830564784054\n",
      "epoch : 7 Accuracy : 0.25021666666666664\n",
      "epoch : 8 batch : 300 loss : 1.3803147077560425\n",
      "Accuracy : 0.2520764119601329\n",
      "epoch : 8 Accuracy : 0.25021666666666664\n",
      "epoch : 9 batch : 300 loss : 1.3584797382354736\n",
      "Accuracy : 0.2549833887043189\n",
      "epoch : 9 Accuracy : 0.25021666666666664\n",
      "epoch : 10 batch : 300 loss : 1.3921797275543213\n",
      "Accuracy : 0.2425249169435216\n",
      "epoch : 10 Accuracy : 0.25021666666666664\n"
     ]
    }
   ],
   "source": [
    "# 학습 진행\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train(MODEL, dataloader, OPTIMIZER, CRITERION, epoch)\n",
    "    accu_val = evaluate(MODEL, dataloader, CRITERION)\n",
    "    print(f\"epoch : {epoch} Accuracy : {accu_val}\")\n",
    "    SCHEDULER.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_NLP38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
